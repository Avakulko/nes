{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### __Monte Carlo Simulation for Derivatives Pricing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "*  __Paul Glasserman, Monte Carlo methods in Financial Engineering__\n",
    "\n",
    "* __Hull textbook: Futures, Options ans other derivatives__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### __Table of Content__\n",
    "\n",
    "#####  1. [Monte Carlo (MC) Method](#mcm)\n",
    "\n",
    "#####  2. [Derivative Pricing ](#der)\n",
    "\n",
    "#####  3. [Pricing Path-Dependent Securities ](#pds)\n",
    "\n",
    "#####  4. [Variance Reduction techniques](#vrt)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='mcm'></a>\n",
    "#### __Monte Carlo (MC) Method__\n",
    "\n",
    "Suppose that $X$ is a r.v. distributed as $X∼D(.)$. The probability density of distribution $D(.)$ is given by function $p(.)$.  \n",
    "  \n",
    "* __Example__: Standard normal distribution.\n",
    "\n",
    "  * In this case $D(x) = N(x)$ and \n",
    "  \n",
    "     $p(x)=\\frac{1}{√2π}\\exp(−\\frac{x^2}{2})$ \n",
    "\n",
    "The expected value of any function $f(X)$ is equal to\n",
    "\n",
    "$E[f (X)] =∫_{Ω}f(x)p(x)dx$\n",
    "\n",
    "<br>\n",
    "\n",
    "##### __MC Estimator__\n",
    "\n",
    "In many cases, this integral can not be calculated analytically and numerical methods are needed.\n",
    "\n",
    "1. We simulate $n$ realization of $X : \\{x_i\\}, i=1,..,n$\n",
    "\n",
    "2. Use $\\hat{f} =  \\frac{\\sum f(x_i)}{ n}$ as an estimator for $E[f(X)]$\n",
    "\n",
    "By strong law of large numbers $\\hat f \\to  E[f(X)]$ with probability 1 as $n → ∞$\n",
    "\n",
    "Let $σ_f$ be the __standard deviation__ of $f(X)$ , then the __error in Monte Carlo estimate__ $\\hat{f} − E[f(X)]$ is approximately normally distributed with mean zero and standard deviation of $\\frac{σ_f}{\\sqrt{n}}$ (by Central limit theorem).\n",
    "\n",
    "Typically, parameter $σ_f$ is unknown. We can estimate it numerically using sample standard deviation:\n",
    "\n",
    "$\\hat{\\sigma}^{2}_{f} =\\frac{1}{n} \\sum_{i} {(f(x_i)-\\hat{f})^{2}}$\n",
    "\n",
    "In practice, it is convenient to calculate it as \n",
    "\n",
    "$\\hat{\\sigma}^{2}_{f} = \\bar{f^2}-\\hat{f}^{2}$, where $\\bar{f} =  \\frac{\\sum f_i^{2}}{ n}$\n",
    "\n",
    "To achieve higher precision (decrease the standard error) we need to increase the sample size $n$ (number of simulations). Convergence of Monte Carlo is of order $\\frac{1}{\\sqrt{n}}$ (the standard error as a function of number of simulations).\n",
    "\n",
    "It means to improve the precision by one digit we need to increase the\n",
    "number of simulation by 100 times. \n",
    "\n",
    "But Monte Carlo $O(\\frac{1}{\\sqrt{n}})$ convergence rate holds for all $d$.\n",
    "\n",
    "In contrast, the error in a numerical integration in $d$ dimensions is $O(n^{-2/d})$ for\n",
    "twice continuously differentiable integrands; this degradation in convergence\n",
    "rate with increasing dimension is characteristic of all deterministic integration\n",
    "methods.\n",
    "\n",
    "Valuing a derivatives by Monte Carlo typically involves simulating paths of stochastic processes for the evolution of an underlying asset prices. The dimension will be at least as large as the number of time steps in the simulation, which is large, and makes the square-root convergence rate for Monte Carlo competitive with alternative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='der'></a>\n",
    "\n",
    "#### __Derivative Pricing__\n",
    "\n",
    "Consider a European style derivative with payoff function at maturity $f(S_T)$.\n",
    "\n",
    "In the risk-neutral world the stock price follows the process: $dS_t = rS_t dt + σ S_t dB_t$\n",
    "\n",
    "The final realization of stock price at time $T$: $S_T$ is a lognormal r.v.:\n",
    "\n",
    "$S_T = S_0 \\exp{((r-\\sigma^2/2)T + \\sigma\\sqrt{T} \\epsilon})$\n",
    "\n",
    "\n",
    "We calculate the prices of European style derivatives as the discounted\n",
    "expectation of its payoff in the risk-neutral world.\n",
    "\n",
    "$P_{f} = e^{-rT}E[f(S_T)] =∫^{\\infty}_{0}f(S_T)p(S_T)dS_T$, where  where $p(.)$ is distribution density function of $S_T$ .\n",
    "\n",
    "##### __MC estimation__:\n",
    "\n",
    "1. We simulate $n$ realization of $S_T : \\{s^i_T\\}, i=1,..,n$\n",
    "\n",
    "2. The MC estimate for the derivative price is computed as\n",
    "\n",
    "$\\hat{P_{f}} = e^{-rT} \\frac{\\sum f(s^i_T)}{ n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='pds'></a>\n",
    "\n",
    "#### __Pricing Path-Dependent Securities__\n",
    "\n",
    "Suppose we want to price a European-style claim contingent on paths of the underlying asset price process. The payoff of the claim at time $T$.\n",
    "\n",
    "$f_T = F(S_t,0⩽S_t⩽S_T)$ depends on the price path from $0$ to $T$. \n",
    "<br>\n",
    "\n",
    "The risk-neutral pricing formula gives the price at time $0$ as a discounted\n",
    "expectation:\n",
    "\n",
    "  $f_{0} = e^{-rT}E[F(S_t,0⩽S_t⩽S_T)]$\n",
    "\n",
    "The expectation is calculated over all possible paths of the risk-neutral process\n",
    "from $0$ to $T$ starting at $S_0$ at time $t=0$. We can estimate this expectation as follows:\n",
    "\n",
    "1. Divide the path into $m$ time steps $Δt = T/m$ , and simulate $n$ sample paths of the risk neutral price process. \n",
    "\n",
    "2. Calculate the terminal payoff for each path. The payoff on the ith path:\n",
    "\n",
    "  $\\{s^i_{k},\\;k=1,..,m \\}$  is\n",
    "\n",
    "  $f^{i}_{0} = F(s^i_{0},..,s^i_{k},..s^i_{m})$\n",
    "\n",
    "3. A Monte Carlo estimate of the security price is just the discounted average of all $n$ payoffs, one for each sample path you generated: \n",
    "\n",
    "    $\\hat{f_{0}} = e^{-rT} \\frac{\\sum f^i}{ n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='vrt'></a>\n",
    "#### __Variance Reduction techniques__\n",
    "\n",
    "Because the convergence of MC method is rather slow, we need to use variance reduction techniques to decrease computational time.\n",
    "\n",
    "<br>\n",
    "\n",
    "##### __Antithetic variables__\n",
    "\n",
    "The simplest and at the same time very effective technique is antithetic variables.\n",
    "\n",
    "Suppose the payoff of a derivative is the r.v. which is expressed as a function of\n",
    "the uniformly distributed variable $U ∼ U(0,1)$ , or $F=h(U)$\n",
    "\n",
    "At ith MC trial calculate the value of the derivative as follows:\n",
    "\n",
    "* generate randomly $u_i$ - the realization of $U$\n",
    "\n",
    "* then calculate the value of the derivative at this trial as\n",
    "\n",
    "  $f^{i} = \\frac{f^{i}_1+f^{i}_2}{2}$, where  where $f_1^i= h(u_i)$ and $f_2^i= h(1−u_i)$\n",
    "\n",
    "The MC estimator of the derivative value is calculated by (*).\n",
    "\n",
    "<br>\n",
    "\n",
    "##### __Stratification__\n",
    "\n",
    "We need to estimate $E(X)$\n",
    "\n",
    "Let $A_1, A_2,.., A_m$ be disjoint subsets of the real line for which $P(X∈ \\cap {A_k}) = 1$\n",
    "\n",
    "Then $E(X) = ∑_{k}P(X∈A_k) E(X|X ∈A_k) = ∑_k p_k E(X|X ∈ A_k)$\n",
    "\n",
    "In random sampling fraction of realizations of $X$ falling in $A_k$ is not equal to $p_k$. In stratified sampling, the fractions are set exogenously.\n",
    "\n",
    "* For example, in proportional sampling, the fractions are equal to population probabilities $p_k$.\n",
    "\n",
    "__Example: Stratifying uniforms__.\n",
    "\n",
    "Partition the unit interval $(0,1)$ into the n strata:\n",
    "\n",
    "$A_1= (0,\\frac{1}{n}], A_2 = (\\frac{1}{n},\\frac{2}{n}],.., A_n = (\\frac{n-1}{n},1]$\n",
    "\n",
    "Let $V_i =\\frac{i−1}{n}+\\frac{u_i}{n},\\;\\; u_i∼U(0,1)$\n",
    "\n",
    "${V_i}, i=1,.., n$ is a stratified sample from the uniform distribution\n",
    "\n",
    "Using that $X = h(U)$, the MC estimator is equal to $\\hat{X} = \\frac{∑_i h(V_i)}{n}$\n",
    "\n",
    "<br>\n",
    "\n",
    "##### __Importance Sampling__\n",
    "\n",
    "Importance sampling reduces variance by changing the probability measure from\n",
    "which r.v. are generated.\n",
    "\n",
    "Consider the problem of estimating $E[f (X)] =∫f(x)p(x)dx$\n",
    "\n",
    "Let $g$ be any other probability density, which satisfies $p(x)>0 ⇒ g(x)>0$\n",
    "\n",
    "Then $E[f(X)] =∫f(x)\\frac{p(x)}{g(x)}g(x)dx$\n",
    "\n",
    "This integral can be interpreted as an expectation with respect to the density $g$\n",
    "\n",
    "$\\tilde E[f(X)\\frac{p(X)}{g(X)}]$, where where $\\tilde E$ the expectation is taken with $X$ distributed according to $g(.)$\n",
    "\n",
    "By selecting $g(.)$, which reduces variance of $f(X)\\frac{p(X)}{g(X)}$, we can reduce the error of the MC estimator.\n",
    "\n",
    "<br>\n",
    "\n",
    "##### __Quasi-Monte-Carlo (QMC)__\n",
    "\n",
    "Alternative to Monte-Carlo method is known as quasi-Monte-Carlo (QMC).\n",
    "\n",
    "In contrast to MC, this method does not mimic randomness. In QMC, to achieve a\n",
    "faster convergence, the random sample of MC is replaced by a sequence of evenly\n",
    "distributed points. \n",
    "\n",
    "QMC has the potential to accelerate convergence from $O(\\frac{1}{\\sqrt{n}})$ to nearly $O(\\frac{1}{n})$\n",
    "\n",
    "The tools used to develop are based on number theory, rather than probability\n",
    "theory and statistics.\n",
    "\n",
    "In ordinary Monte Carlo simulation, taking a scalar i.i.d. sequence of uniforms $U_1, U_2,..$ and forming vectors $(U_1,...,U_d), (U_{d+1},...,U_{2d}),..$ produces an i.i.d. sequence of points from the d-dimensional hypercube.\n",
    "\n",
    "In QMC general, these d-dimensional vectors are presented by low-discrepancy numbers (for\n",
    "example, Sobol numbers), which fill the d-dimensional cube in a particular\n",
    "evenly distributed way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
